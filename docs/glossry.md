# PyTorch/XLA دليل المصطلحات

يحدد هذا دليل المصطلحات الشائعة المستخدمة في وثائق PyTorch/XLA.

## A

**معالج تسريع** - مكون عتاد مخصص مصمم لتسريع مهام حسابية محددة، مثل التعلم العميق. تشمل الأمثلة وحدات معالجة الرسوميات (GPUs) ووحدات معالجة الدفعة (TPUs).

## B

**حاجز**: في سياق PyTorch/XLA، هي نقطة تزامن تضمن اكتمال جميع العمليات على tensors XLA قبل المتابعة. ويُستخدم غالبًا للتأكد من أن المضيف (وحدة المعالجة المركزية) والجهاز (TPU/GPU) متزامنان.

**bfloat16**: نوع بيانات عائم بنقطة عائمة مكون من 16 بت يُستخدم بشكل شائع في وحدات معالجة الدفعة (TPUs) لتدريب أسرع.

## C

**CUDA**: منصة حوسبة متوازية ونموذج برمجة طورهما NVIDIA لاستخدامهما مع وحدات معالجة الرسوميات (GPU).

**مجموعة عمليات Core Aten**: مجموعة من العمليات الأساسية من مكتبة ATen في PyTorch تعتبر أساسية للوظائف الأساسية وتصدير النماذج.

## D

**التكرار المتوازي للبيانات**: استراتيجية موازية يتم فيها تكرار نفس النموذج على أجهزة متعددة، حيث تقوم كل جهاز بمعالجة مجموعة فرعية مختلفة من بيانات التدريب.

**شبكة الأجهزة**: تمثيل منطقي للأجهزة المترابطة (TPUs/GPUs) المستخدمة للتدريب الموزع، والذي يحدد ترتيب أجهزة الاتصال ومساراتها.

**DistributedDataParallel (DDP)**: وحدة نمطية PyTorch تتيح التدريب المتوازي للبيانات عبر أجهزة متعددة، ويتم استخدامها عادةً بالاقتران مع torch.distributed.

**Distributed Tensor**: واجهة برمجة التطبيقات (API) في PyTorch لتمثيل tensors الموزعة عبر أجهزة متعددة، مما يسهل الحساب المتوازي والموزع.

**دينامو** (انظر **TorchDynamo**)

## E

**التنفيذ التواقتي**: نموذج حسابي يتم فيه تنفيذ العمليات فورًا عند مواجهتها في التعليمات البرمجية، على عكس تنفيذ الرسم البياني.

**متغيرات البيئة**: متغيرات يمكن تعيينها خارج البرنامج للتحكم في سلوكه، ويتم استخدامها غالبًا في PyTorch/XLA لتكوين خيارات وقت التشغيل.

## F

**FSDP (Fully Sharded Data Parallel)**: تقنية تدريب متوازي للبيانات تقوم بتجزئة معلمات النموذج والتدرجات وحالات المحسن عبر الأجهزة.

**FX (TorchFX)**: تنسيق تمثيل وسيط (IR) المستخدم في PyTorch لتمثيل مخططات الحساب بطريقة أكثر تنظيماً.

**الوظيفية**: عملية تحويل التعليمات البرمجية لتنفيذ التواقت إلى تمثيل وظيفي، مما يسمح بفرص أكبر للتحسين والترجمة.

## G

**GSPMD (General and Scalable Parallelization for ML Computation Graphs)**: واجهة برمجة تطبيقات (API) واحدة تمكّن مجموعة كبيرة من خوارزميات التوازي (بما في ذلك التوازي المتوازي للبيانات، والتوازي المتوازي الكامل للبيانات، وتقسيم الفضاء، وتوازي الأنابيب، بالإضافة إلى مجموعات من هذه الخوارزميات) لمختلف أعباء العمل في مجال التعلم الآلي وهندسات النماذج.

## H

**HLO (High-Level Optimizer)**: تنسيق تمثيل وسيط (IR) يستخدمه مترجم XLA، ويمثل مخطط حساب بمستوى أعلى من لغة الآلة.

**Hugging Face**: مجتمع ومنصة توفر أدوات وموارد لمعالجة اللغات الطبيعية، بما في ذلك النماذج المدربة مسبقًا وواجهة برمجة تطبيقات (API) Trainer الشهيرة.

## I

**IR (Intermediate Representation)**: تمثيل لبرنامج أو مخطط حساب أكثر تجريدًا من لغة الآلة ولكنه أقرب إليه من التعليمات البرمجية المصدر الأصلية.

## J

**JAX**: مكتبة حوسبة عددية عالية الأداء طورتها Google، تشتهر بالتفاضل التلقائي وتكامل XLA.

**JIT (Just-in-Time Compilation)**: استراتيجية ترجمة يتم فيها ترجمة التعليمات البرمجية في وقت التشغيل، حسب الحاجة، مما يوفر المرونة والتحسينات المحتملة بناءً على معلومات وقت التشغيل.

## K

**Kaggle**: مجتمع ومنصة عبر الإنترنت لممارسي التعلم الآلي لمشاركة التعليمات البرمجية والحلول.

## L

**Lazy Tensor**: نوع من tensor في PyTorch/XLA يؤخر تنفيذ العملية حتى تكون النتائج مطلوبة بشكل صريح، مما يسمح بتحسين الرسم البياني وترجمة XLA.

**Lit-GPT**: ينفذ نماذج اللغة مفتوحة المصدر الكبيرة في XLA ويدعم الضبط الدقيق

## M

**التوازي النموذجي**: استراتيجية موازية يتم فيها توزيع أجزاء مختلفة من نموذج عبر أجهزة متعددة، مما يمكّن من تدريب نماذج كبيرة جدًا بحيث لا يمكنها أن تتسع لجهاز واحد.

**تعدد المعالجة**: تقنية برمجة لتشغيل عمليات متعددة بشكل متزامن، ويتم استخدامها غالبًا في PyTorch/XLA لاستخدام أنوية TPU متعددة.

**MpDeviceLoader**: أداة PyTorch/XLA لتحميل البيانات وتوزيعها بكفاءة عبر أجهزة متعددة أثناء التدريب.

## N

**NCCL (NVIDIA Collective Communications Library)**: مكتبة لعمليات الاتصال الجماعي الفعالة (مثل all-reduce، all-gather) على وحدات معالجة الرسوميات (GPUs) الخاصة بشركة NVIDIA.

## O

**OpenXLA**: مشروع مفتوح المصدر يهدف إلى تطوير وصيانة XLA، وهو مترجم التعلم العميق.

**Ordinal**: معرف فريد لجهاز (TPU/GPU) داخل إعداد تدريب موزع، ويستخدم غالبًا لتحديد دور الجهاز وتقسيم البيانات.

## P

**محدد التقسيم**: في GSPMD، مواصفات تحدد كيفية تجزئة tensor عبر شبكة الأجهزة.

**PJRT (Portable JAX Runtime)**: بيئة وقت تشغيل لـ JAX تدعم وحدات خلفية متعددة.

**Pod**: مجموعة من مضيفي TPU المترابطين، توفر نطاقًا واسعًا لتدريب النماذج الكبيرة.

**الاستيلاء**: حدث يتم فيه استرداد Cloud TPU بواسطة موفر السحابة، مما يتطلب نقطة تفتيش لتجنب فقدان تقدم التدريب.

## R

**Rendezvous**: يستخدمها Torch Distributed Elastic لجمع المشاركين في مهمة تدريب (أي العقد) بحيث يتفقون جميعًا على نفس قائمة المشاركين وأدوار الجميع، وكذلك اتخاذ قرار جماعي متسق بشأن متى يمكن بدء/استئناف التدريب.

**التكرار**: استراتيجية توزيع البيانات حيث يتم نسخ tensor بالكامل إلى جميع الأجهزة الموجودة في الشبكة، مما يضمن أن تحتوي جميع الأجهزة على نفس البيانات.

## S

**التجزئة**: عملية تقسيم tensor إلى قطع أصغر (شظايا) وتوزيعها عبر الأجهزة، والتي تستخدم غالبًا لتقليل البصمة الذاكرية وتمكين الحساب المتوازي.

**SPMD (Single Program, Multiple Data)**: نموذج برمجة متوازي يتم فيه تنفيذ نفس البرنامج على أجهزة متعددة.

**State Dict**: كائن قاموس Python يقوم بتعيين كل طبقة إلى tensor المعلمة الخاصة بها. ويستخدم لحفظ النماذج أو تحميلها.

## T

**TensorBoard**: أداة تصور لمراقبة وتحليل تقدم التدريب، بما في ذلك مقاييس الأداء ومخططات الحساب.

**TorchDynamo**: مترجم JIT على مستوى Python لـ PyTorch، يقوم بتعديل البايت كود ديناميكيًا لتمكين التقاط الرسم البياني والتحسين.

**وحدة معالجة الدفعة (TPU)**: معالج تسريع التعلم الآلي المصمم خصيصًا والذي طورته Google، والذي يوفر أداءً عاليًا لأعباء عمل التعلم العميق.

## X

**XLA (Accelerated Linear Algebra)**: مترجم تعلم عميق طورته Google.

**XLATensor**: نوع tensor في PyTorch/XLA يمثل بيانات على جهاز XLA، مما يمكّن التنفيذ البطيء وترجمة XLA.

**xla_device()**: وظيفة PyTorch/XLA لاسترداد جهاز XLA الحالي.

**xm (xla_model)**: وحدة نمطية في PyTorch/XLA توفر وظائف أساسية للتفاعل مع أجهزة XLA وتنفيذ الحسابات.

**xmp (xla_multiprocessing)**: وحدة نمطية في PyTorch/XLA لبدء عمليات التدريب الموزعة عبر أحدات XLA متعددة.