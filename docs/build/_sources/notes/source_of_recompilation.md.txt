مصدر إعادة التجميع في torch_xla

دعونا نبدأ أولا ببعض الحقائق/القيود:

1. عمليات تجميع الرسوم البيانية في XLA مكلفة للغاية.
2. XLA يتعامل مع الشكل الثابت فقط. وبعبارة أخرى، حتى لنفس رسم IR، XLA يعيد التجميع عند تغيير شكل الإدخال.
3. تؤثر عمليات إعادة التجميع سلبًا على أداء torch_xla بشكل كبير عندما تحدث، ومن الصعب فهمها وإصلاحها من وجهة نظر المستخدم العادي لـ Python.

غالبًا ما نقول عندما تحدث عملية إعادة التجميع، إننا نحتاج فقط إلى دعم الشكل الديناميكي، ثم نطمئن إلى أنه عندما يتم دعم الشكل الديناميكي في المستقبل، ستختفي جميع عمليات إعادة التجميع بشكل سحري. لكن هذا غير صحيح، حيث أن XLA لديه بالفعل تغطية جيدة جدًا للأشكال الديناميكية المحدودة، ولكننا ما زلنا نرى عمليات إعادة التجميع وهي متوقعة.

تهدف هذه الوثيقة إلى تقديم شرح مفصل لبعض المصادر الشائعة لإعادة التجميع، وما نحتاج إلى فعله للتخلص منها. ستركز بشكل أساسي على شرح المشكلة للمبتدئين دون أي سياق. لتسهيل الفهم، قد تعتمد "الحلول" المقترحة هنا على افتراضات غير عملية.

#1. من مجموعة البيانات المدخلة

نعم، من الشائع جدًا أن تحتوي مجموعة البيانات المدخلة على أمثلة بأشكال مختلفة، مثل الجمل ذات الأطوال المختلفة أو الصور بأحجام مختلفة. بدون التوحيد القياسي، سيؤدي ذلك إلى إعادة تجميع لكل شكل إدخال جديد.

عادة ما يقوم مستخدمو وضع الرسم البياني TensorFlow بإجراء التعبئة/التقسيم إلى دلو (tf.pad) لتوحيد أشكال الإدخال إلى دلو واحد أو عدد قليل من الدلاء. ولكن هذا يتعارض مع نمط مستخدمي واجهة PyTorch الأمامية المتحمسين (والذي يستهدف واجهة المستخدم الأمامية للتوتر الكسول أيضًا) نظرًا لأن أشكال الإدخال المختلفة لا تهم الواجهة الخلفية لـ CPU/CUDA المتحمسة.

حل بديل مقترح: حسنًا، دعنا نقول إننا يمكننا حل هذه المشكلة عن طريق تعليم مستخدمينا إجراء التعبئة/التقسيم إلى دلو (من الصعب القيام بذلك عمليًا :P). ما التالي؟

#2. من إخراج المشغل

هناك بعض المشغلات التي تكون ديناميكية من الناحية الدلالية وتنتج أشكال إخراج ديناميكية: على سبيل المثال، يعيد torch.nonzero المؤشرات إلى العناصر غير الصفرية في موتر الإدخال الخاص به. لذلك، حتى إذا كانت موترات الإدخال لهذا المشغل دائمًا بنفس الشكل، فقد ينتج أشكال إخراج مختلفة ويتسبب في عمليات إعادة تجميع.

2.1 يمكن أن يصلح الشكل الديناميكي المحدود الحالة التي تستخدم فيها الموتر ذو الشكل الديناميكي كموتر، دون الاستعلام عن أبعاده الفعلية.

حل بديل مقترح: دعنا نقول الآن أن XLA يدعم الشكل الديناميكي المحدود لجميع المشغلين، فهل هذا جيد بما فيه الكفاية؟

* يعني الشكل الديناميكي المحدود أنه يمكننا تعبئة الموتر إلى الحد الأقصى النظري، مما يؤدي إلى زيادة استخدام الذاكرة مقابل تقليل إعادة التجميع/زيادة السرعة.

حسنًا، إلى حد ما. دعنا نرى المثال التالي:

```
a = torch.tensor([1, 2, 0, 1, 3], device='xla')
b = torch.nonzero(a)
c = b * 2
d = c + 1
print(torch_xla._XLAC._get_xla_tensors_text([d]))
```

في المثال أعلاه، سيكون لكل عقدة أسفل "b" في الرسم البياني (بمعنى "c" و"d" وكل ما يعتمد عليهما) شكل ديناميكي، ومن الواضح أن "b" له شكل ديناميكي في البعد 0 كما هو موضح أدناه:

```
%9 = (s64[<=5,1]{1,0}, s64[]) aten::nonzero(%8), num_outputs=2 # b
%10 = s64[5,1]{1,0} aten::mul(%9.0, %3) # c
%11 = s64[5,1]{1,0} aten::add(%10, %2), ROOT=0 # d
```

على الرغم من أنه لا يتم عرضه مباشرة في الرسم البياني، فإن "c" و"d" لهما أيضًا شكل ديناميكي (بعبارة أخرى، [5، 1] هو الشكل المبطن فقط وهو مقنع).

```
print(torch_xla._XLAC._get_xla_tensor_dimension_size(d, 0)) # prints 4 instead of 5
```

يمكنك أن ترى أنه في هذه الحالة، طالما أن موتر الإدخال "a" له الشكل [5]، فإننا نقوم بتجميع الرسم البياني مرة واحدة فقط. ساعد دعم الشكل الديناميكي المحدود!

2.2 ماذا لو تم الاستعلام عن البعد الفعلي على موتر ذي شكل ديناميكي؟

يتم استخدام هذا بالفعل بشكل شائع نظرًا لأن حسابات PyTorch لا تتم جميعها على شكل موترات.

على سبيل المثال، تعيد tensor.size() في PyTorch مجموعة من الأعداد الصحيحة بدلاً من موتر من dtype=int. عندما يكون "الموتر" موترًا ذا شكل ديناميكي، فإن هذا المشغل يجبر XLA فعليًا على قطع الرسم البياني وتقييمه حتى نتمكن من إعادة القيمة الصحيحة (وإلا فإنه سيعيد الشكل المبطن فقط وهو خطأ).

ما زاد الأمر سوءًا هو أن العديد من PyTorch يأخذ إدخالات قياسية أيضًا. بعد أن تقوم بـ s = tensor.size(0) وتستخدم "s" في مشغلين آخرين، فإنه يصبح مصدرًا ديناميكيًا أيضًا. في هذه الحالة، ربما نعرف كيفية تعبئتها وحدودها العليا، ولكن لا يمكننا القيام بذلك لأنها ليست موترًا حتى!

```
a = torch.tensor([1, 2, 0, 1, 3], device='xla')
b = torch.nonzero(a)
s = a.size(0) # يحدث التقييم! ملاحظة: نستخدم size() للتبسيط، واجهة برمجة التطبيقات الفعلية هي _get_xla_tensor_dimension_size.
c = torch.rand(s, device='xla') # يمكن أن يكون c بأي شكل بين [0، 5] مما يتسبب في المزيد من عمليات إعادة التجميع!
d = c + 1
```

لذلك، من الصعب حل هذه المشكلة دون مساعدة واجهة PyTorch الأمامية. ماذا نحتاج؟

باختصار، نحتاج إلى عالم موتر!

على سبيل المثال،

* يجب أن تعيد tensor.size() موترًا حتى يمكن أن يكون موترًا ذا شكل ديناميكي ويظل في الرسم البياني دون تقييم مبكر.
* موتر الملحق، على سبيل المثال لموتر ثنائي الأبعاد، tensor[0][0] يعيد الآن قيمة ولكن هذا يجب أن يعيد موترًا أيضًا.
* ضمنيًا، يعني ذلك أن جميع المشغلين الذين يقبلون int/float/double كإدخال يحتاجون إلى زيادة الحمل الزائد للموتر أيضًا. هذا طلب كبير لأنه يمكن أن يزيد بسهولة مجموعة المشغلين لدينا.
* من الأسهل إذا كان من الممكن جعل تحويل القيمة القياسية إلى موتر رخيصًا جدًا حتى نتمكن من الاهتمام فقط بزيادة الحمل الزائد للموتر.
* في الممارسة العملية، لا تأخذ جميع المشغلين قياسات من الحسابات السابقة، لذا فقد كنا نضيف متغيرات الموتر عن طريق طلبات مخصصة.
* هذا أيضًا طلب شائع من نهج التتبع الأساسي أعتقد.

حسنًا، الآن افترض أن كل عملية في PyTorch لديها إصدار Tensor نحتاجه، هل انتهينا؟

#3. من تدفق التحكم

كلا! لقد قمنا بالفعل بحل المشكلة دون تدفق تحكم يعتمد على البيانات...

انظر المثال أدناه:

```
if x[0][0] == 3:
bla
else:
blabla
```

حتى إذا كان x[0][0] موترًا، فيجب علينا تنفيذ/تجسيد قيمته حتى يتمكن مفسر Python من الاستمرار. واختيار فرع مختلف في تدفقات التحكم المتعددة مجتمعة يعني أن لدينا الكثير من الرسوم البيانية لتجميعها أيضًا!

في الوقت الحالي، ليس لدينا طريقة لإصلاح ذلك. لإصلاحه، نحتاج إلى تقليل تدفق التحكم من Python إلى الرسم البياني! دون الكثير من التفكير في التنفيذ، يمكننا القيام بذلك بطريقتين:

* اطلب من المستخدمين استخدام مشغل تدفق تحكم بشكل صريح بدلاً من Python if/else/while/for. هذا مدعوم حاليًا كـ [واجهة برمجة تطبيقات مخصصة في torch_xla](https://github.com/pytorch/xla/blob/master/torch_xla/core/xla_builder.py#L563-L574) ولكنه غير مُعتمد على نطاق واسع في رمز المستخدم. (اعتاد مستخدمو Python على if/else/for ومن الصعب تحويلهم إلى واجهة برمجة تطبيقات أكثر قبحًا ما لم يكن هناك فوز كبير في الأداء).
* قم بتفسير رمز مصدر Python للحصول على بيان تدفق التحكم تلقائيًا. هذا مثل Torchscript وبطريقة ما قم بدمج الرسم البياني لـ Torchscripted في الرسم البياني الذي يتم تتبعه بإهمال (بما في ذلك معلومات الشكل وما إلى ذلك). لم أفكر في خطوات التنفيذ بالفعل :P

ولكن يتطلب أي حل أعلاه قدرًا غير قليل من الجهد، إما على جانب المستخدم أو على جانب الإطار. ولهذا نتحمل حاليًا ضربة التقييم المبكر وعمليات التجميع المتعددة كحل قصير الأجل بالنطاق الترددي الذي نمتلكه.

حسنًا، لذا افترض الآن أن لدينا أيضًا تدفق تحكم مخفض في الرسم البياني تلقائيًا، هل نحن جاهزون؟

نعم! الآن لديك كل حساباتك ممثلة في رسم بياني لعمليات موتر، بما في ذلك تدفق التحكم بحيث يمكن للمترجمين الآن استهلاكها والقيام بالحيل الذكية الخاصة بهم! ولكن بصراحة، في هذه المرحلة، لم يعد برنامجك يشبه PyTorch.

الخلاصة:

هناك في الواقع مصادر متعددة لإعادة التجميع ولا يمكن أن يحل الشكل الديناميكي المحدود كل ذلك. الحلول البديلة المقترحة في هذه الوثيقة غير عملية في بعض الأحيان، وقد تكون هناك طرق أفضل لإصلاح كل مصدر بشكل صحيح لا أعرفه على الإطلاق. ولكن آمل أنه مع استمرارنا في شق طريقنا إلى مكدس التوتر الكسول المثالي في هذه الوثيقة، أصبح من الأسهل الآن فهم العقبات المتبقية أمامنا.

التذييل:

1. يستخدم NNC الأشكال الرمزية، فهل هذا يساعد؟

نعم ولكن جزئيًا. من خلال وجود شكل رمزي، لم تعد عملية تحسين التجميع تتطلب قيم أشكال ملموسة. وبعبارة أخرى، فإن نواة المولد أكثر عمومية من نوى الأشكال الثابتة لـ XLA.

وما هي المشكلة التي يساعد ذلك على حلها بالضبط؟

إنه يساعد في الحالات مثل #1 و #2.1.

```
الشكل [3، 5] -> إضافة -> عبر -> ... -> مضروب
الشكل [6، 2] -> إضافة -> عبر -> ... -> مضروب

# مع الشكل الرمزي
الشكل [x، y] -> إضافة -> عبر -> ... -> مضروب
```

مع الشكل الرمزي، لا يعيد نواة المولد التجميع كما تفعل XLA مع الأشكال الثابتة.

تحل XLA هذه المشكلة بطريقة أخرى، باستخدام التعبئة/التقسيم إلى دلو (لـ #1) والشكل الديناميكي المحدود (لـ #2.1).

طرح Brian Hirsh (@bdhirsh) بعض الأسئلة الجيدة حقًا في التعليق، والانتقال من هنا إلى جعلها أكثر وضوحًا:

2. هل يستحق الأمر وضع TORCH_WARN في نوى XLA للمشغلين الذين ينتجون أشكال إخراج تعتمد على البيانات؟

نعم، من المفيد أن يخبر المستخدمين "هاي، لن يعمل برنامجك بسرعة كبيرة". ولكن بالنسبة لهذه المشغلين المعتمدين على البيانات، لا توجد إعادة كتابة سهلة لهم ما لم يغير المستخدمون المنطق في نموذجهم. (مثال آخر هو torch.unique())

3. كيف تؤثر المشغلين مثل nonzero على قدرتنا على إلغاء الظاهرية sizes()؟ إذا أردنا إلغاء الظاهرية sizes()، فسوف نحتاج إلى القدرة على حساب الأحجام بشكل متلهف لكل عملية - ألا يعني ذلك أننا مجبرون على تقييم الرسم البياني في كل مرة نصادف فيها عملية مثل nonzero؟ مقابل في الوقت الحالي، يبدو أننا لا نجبر التقييم فعليًا عندما يستدعي المستخدم nonzero()؟

سؤال رائع! لذلك، في الشكل الحالي، فهو ليس حاصرا صعبًا نظرًا لأن size() على موترات XLA لا تحمل معلومات حجم الحقيقة. كما هو موضح في المثال، فإن مصدر الحقيقة يعيش في IRValue ويمكن استرجاعه بواسطة _get_xla_tensor_dimension_size فقط. لذا، إذا قررنا إلغاء الظاهرية size، فسيفرض ذلك هذا التباين.

كمتابعة، إذا كان لدينا size() لإعادة موتر بدلاً من القيم كما هو مذكور في الحلول البديلة المقترحة أعلاه. في هذه الحالة، لن تتمكن size() من إلغاء الظاهرية نظرًا لأنها تصبح مشغلًا (يأخذ موتر كإدخال وينتج موتر، ولديه عمليات تنفيذ مختلفة لواجهات خلفية مختلفة.)

4. إذا قمت، على سبيل المثال، باستدعاء `torch.add(input، 1)` في حلقة، حيث يختلف الإدخال في الحجم من 1 إلى 1000، فعادة ما يتعين علينا تجميع 1000 رسم بياني مختلف - ولكن مع الأشكال الديناميكية، يبدو أن XLA ستتمكن داخليًا من إنشاء رسم بياني واحد حيث تقول "استخدم هذا الرسم البياني إذا كان حجم الإدخال <=1000". سؤالي هو: هل "الشكل الديناميكي" خاصية الرسم البياني فقط؟ أو من الرسم البياني والإدخال. بمعنى إذا كان رمزي هو `x = torch.add(input، 1)؛ x.sizes()` في حلقة، فهل لدى x شكل ديناميكي في هذه المرحلة، مما يعني أننا سنحتاج إلى تشغيل الرسم البياني للحصول على الأحجام؟ أو هل يمكننا جعله خاصية محسوبة بإهمال حتى في وجود رسوم بيانية ذات أشكال ديناميكية.

نعم، في هذه الحالة، ستجمع 1000 رسم بياني مختلف. تعني الأشكال الديناميكية أن إدخالها يحتوي على بُعد ديناميكي. لذا، عند الاستعلام عن `x.sizes()` (حاليًا يجب استخدام get_dimention_size للحصول على الحجم الصحيح) فإنه سيؤدي إلى تشغيل *التنفيذ* (نظرًا لأن الحجم لم يتغير، فإنه لا يؤدي إلى إعادة التجميع). بدون السطر الذي يصل إلى الحجم، فلن يؤدي إلى أي إعادة تجميع/تنفيذ عندما يكون للإدخال بُعد ديناميكي.

5. هل سيكون البديل لجعل تدفق التحكم متاحًا في الرسم البياني هو مجرد التوصل إلى طريقة لضمان عدم احتواء رسوم XLA البيانية على تدفق التحكم؟ أي إذا كان لدينا نموذج به شرط واحد في المنتصف، فاجعل XLA ينتج 3 رسوم بيانية: 1 لكل شيء قبل الشرط، و1 لفرع if، و1 لفرع else. وهذا يعني أنك لا تحصل على الانفجار الأسي لرسوم بيانية جديدة لكل مجموعة من المسارات المتخذة، ولكن (أ) الرسوم البيانية أصغر وتوفر فرص تحسين أقل، و(ب) سيكون من الصعب جدًا جعل XLA يتعرف على المكان الذي يتم فيه اتخاذ مسار شرطي.

نقطة عظيمة! لذلك، إذا تمكنا من تقسيمها إلى رسوم بيانية أصغر، فمن الممكن القيام بذلك. ولكن في الممارسة العملية، هذا النمط مزعج:

```
y = <some computation>
x = y + 2
if x[0] == 2:
z = y +1
else:
z = y - 1
```

لاحظ أنك ستقيم x باستخدام رسم بياني فرعي عند الوصول إلى تدفق التحكم، ولكن قد يكون هناك متغير سابق مدرج في حساب الفرع أيضًا (مثل "y" هو عق